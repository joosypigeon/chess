{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e56509-4174-47d6-a094-a93853d98238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 01:47:28.352101: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-02 01:47:29.060893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-02 01:47:29.894067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 01:47:29.949456: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 01:47:29.949506: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 01:47:29.951109: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 01:47:29.951153: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 01:47:29.951183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 01:47:30.699916: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 01:47:30.699983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 01:47:30.699990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-02 01:47:30.700024: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 01:47:30.700052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5391 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import io\n",
    "import chess.pgn\n",
    "import zstandard as zstd\n",
    "import re\n",
    "from bitboard import bitboard_to_array, bitboards_to_arrays, board_to_bitboards, array_to_bitboard, bitboards_to_board, arrays_to_bitboards\n",
    "\n",
    "# Define a dictionary to map the color values to nice output strings\n",
    "color_names = {\n",
    "    chess.WHITE: \"w\",\n",
    "    chess.BLACK: \"b\"\n",
    "}\n",
    "\n",
    "def data_generator_batch(batch_size):\n",
    "    with open('./data/lichess_db_standard_rated_2023-06.pgn.zst', 'rb') as f:\n",
    "        dctx = zstd.ZstdDecompressor()\n",
    "        reader = dctx.stream_reader(f)\n",
    "        text_stream = io.TextIOWrapper(reader, encoding='utf-8')\n",
    "\n",
    "        dic = {}\n",
    "        \n",
    "        # Initialize lists to store batch data\n",
    "        batch_boards = []\n",
    "        #batch_move_numbers = []\n",
    "        batch_players = []\n",
    "        batch_evals = []\n",
    "        batched_so_far = 0 # when this gets to batch_size, yield the batched data and reset to 0\n",
    "        # Iterate over all games in the PGN file\n",
    "        while True:\n",
    "            number_of_games = 0\n",
    "            \n",
    "            game = chess.pgn.read_game(text_stream)\n",
    "            if game is None:\n",
    "                break\n",
    "            \n",
    "            # Check if the game has embedded Stockfish evaluations\n",
    "            has_evaluations = any('[%eval ' in node.comment for node in game.mainline())\n",
    "            if not has_evaluations:\n",
    "                #print(\"found game with no eval\")\n",
    "                continue\n",
    "\n",
    "            #print(game)\n",
    "            \n",
    "            number_of_games += 1\n",
    "            \n",
    "            # Count the number of moves in the main line\n",
    "            num_moves = sum(1 for _ in game.mainline_moves())\n",
    "            \n",
    "            # Setup initial empty chess board\n",
    "            board = chess.Board()\n",
    "            \n",
    "            # Iterate through all moves of the game\n",
    "            for node in game.mainline():\n",
    "                move = node.move\n",
    "                board.push(move)\n",
    "\n",
    "                fen = board.fen()\n",
    "                if fen in dic:\n",
    "                    dic[fen] += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    dic[fen] = 1\n",
    "\n",
    "                # Get the comment (which contains the evaluation) for this move\n",
    "                comment = node.comment\n",
    "                match = re.search(r\"\\[%eval (.*?)\\]\", comment)\n",
    "                if match is None:\n",
    "                    #print(f\"did not find a match when one was expected.\")\n",
    "                    continue\n",
    "\n",
    "                score_str = match.group(1)\n",
    "                \n",
    "                # Convert mate in 'n' moves to large scores\n",
    "                if '#' in score_str:\n",
    "                    if '-' in score_str:\n",
    "                        score = -15\n",
    "                    else:\n",
    "                        score = 15\n",
    "                else:\n",
    "                    score = float(score_str)\n",
    "                    if score < -15:\n",
    "                        score = -15\n",
    "                    elif score > 15:\n",
    "                        score = 15\n",
    "                        \n",
    "                \n",
    "                # Convert the board position to bitboards and add to list\n",
    "                bitboards = board_to_bitboards(board)\n",
    "                batch_boards.append(bitboards_to_arrays(bitboards))\n",
    "                #batch_move_numbers.append(np.int16(board.ply()))\n",
    "                batch_players.append(np.int8(board.turn))\n",
    "                batch_evals.append(np.float16(score))\n",
    "                batched_so_far += 1\n",
    "                try:\n",
    "                    assert(len(batch_boards) == batched_so_far)\n",
    "                    #assert(len(batch_move_numbers) == batched_so_far)\n",
    "                    assert(len(batch_players) == batched_so_far)\n",
    "                    assert(len(batch_evals) == batched_so_far)\n",
    "                except Exception as e:\n",
    "                    print(\"These should match\", e)\n",
    "                    \n",
    "                #print(f\"game: {number_of_games} move: {board.ply()}/{num_moves} {move.uci()} next: {color_names[np.int32(board.turn)]} score: {np.float16(score)}\")\n",
    "                #print(board)\n",
    "                if batched_so_far == batch_size:\n",
    "                    batched_so_far = 0\n",
    "                    # print(f\"batch_size: {batch_size}\")\n",
    "                    # print(f\"len(batch_boards): {len(batch_boards)}\")\n",
    "                    # print(f\"len(batch_move_numbers): {len(batch_move_numbers)}\")\n",
    "                    # print(f\"len(batch_evals): {len(batch_evals)}\")\n",
    "                    # Convert batch data to numpy arrays\n",
    "                    batch_boards = np.array(batch_boards, dtype=np.int16)\n",
    "                    #batch_move_numbers = np.array(batch_move_numbers, dtype=np.int16)\n",
    "                    batch_players = np.array(batch_players, dtype=np.int8)\n",
    "                    batch_evals = np.array(batch_evals, dtype=np.float16)\n",
    "                    # Yield batch data\n",
    "                    yield ((batch_boards, batch_players), batch_evals)\n",
    "                    # Initialize lists to store batch data\n",
    "                    batch_boards = []\n",
    "                    #batch_move_numbers = []\n",
    "                    batch_players = []\n",
    "                    batch_evals = []\n",
    "  \n",
    "\n",
    "# Use batch generator to create dataset\n",
    "batch_size = 1\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator_batch(batch_size),  # Change 32 to the batch size you want\n",
    "    output_signature=(\n",
    "        (tf.TensorSpec(shape=(None, 8, 8, 12), dtype=tf.int16),\n",
    "         tf.TensorSpec(shape=(None,), dtype=tf.int8)),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float16)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ca1e4-06b0-40c0-8e91-97f69ca0d9ca",
   "metadata": {},
   "source": [
    "for input, scores in dataset.take(1000):\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    batch_of_arrays = input[0].numpy().tolist()\n",
    "    moves = input[1].numpy().tolist()\n",
    "    scores = scores.numpy().tolist()\n",
    "    for list_of_arrays, move, score in zip(batch_of_arrays, moves, scores):\n",
    "        print(\"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\")\n",
    "        bitboards = arrays_to_bitboards(list_of_arrays)\n",
    "        board = bitboards_to_board(bitboards)\n",
    "        print(board)\n",
    "        print(f\"move: {move} score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af712322-f9ea-4d48-9237-1ad6df59d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = 100000\n",
    "dataset_subset = dataset.take(n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dad962d6-c8c0-4c6e-851d-a4163988de77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 8, 8, 12)]           0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 8, 8, 64)             6976      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 8, 8, 64)             256       ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 64)             36928     ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 8, 8, 64)             256       ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 64)             36928     ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 8, 8, 64)             256       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 4096)                 0         ['batch_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 4097)                 0         ['flatten[0][0]',             \n",
      "                                                                     'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 4196352   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  262400    ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 64)                   16448     ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    65        ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4556865 (17.38 MB)\n",
      "Trainable params: 4556481 (17.38 MB)\n",
      "Non-trainable params: 384 (1.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# input shape for the board is 8x8x12\n",
    "board_input = layers.Input(shape=(8, 8, 12))\n",
    "\n",
    "# input for the move number is a single scalar\n",
    "move_number_input = layers.Input(shape=(1,))\n",
    "\n",
    "# Add several convolutional layers to process the board\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(board_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Flatten()(x)\n",
    "# Concatenate the processed board and move number inputs\n",
    "x = layers.Concatenate()([x, move_number_input])  # move_number_input is directly used here\n",
    "\n",
    "# Add more fully-connected layers\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "#x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "# Add an output layer, assuming we're doing regression to predict the evaluation score\n",
    "output_layer = layers.Dense(1)(x)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(inputs=(board_input, move_number_input), outputs=output_layer)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model, using mean squared error as the loss function for regression\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91abbb7e-39c5-4d4e-a622-345889289435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(fen):\n",
    "    board = chess.Board(fen)\n",
    "    move_number_int = np.int16(board.turn)\n",
    "    bb = bitboards_to_arrays(board_to_bitboards(board))\n",
    "    bb = np.array([bb])\n",
    "    pp = np.array([move_number_int])\n",
    "    prediction = model.predict((bb, pp), verbose = 0)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4cc2b0-b71c-4883-aee0-28191ae36a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 01:47:32.462985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: -1 Opera prediction: [[-0.00612149]]\n",
      "i: -1 Donald Byrne and Bobby Fischer 1956 prediction: [[-0.02357017]]\n",
      "i: -1 Garry Kasparov and Anatoly Karpov 1985 prediction: [[-0.02122227]]\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 01:47:33.769880: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-02 01:47:34.704115: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fcd600033f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-02 01:47:34.704152: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2023-08-02 01:47:34.709883: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-02 01:47:34.802314: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  99998/Unknown - 666s 7ms/step - loss: 27.1190"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 01:58:39.448984: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 8887355775821314107\n",
      "2023-08-02 01:58:39.449032: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 9635292581005224981\n",
      "2023-08-02 01:58:39.449039: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 15612155083775079529\n",
      "2023-08-02 01:58:39.449061: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous recv item cancelled. Key hash: 6922649183025778868\n",
      "2023-08-02 01:58:39.731213: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1006878720 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 666s 7ms/step - loss: 27.1187\n",
      "Epoch 2/10\n",
      " 99997/100000 [============================>.] - ETA: 0s - loss: 34.8562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 02:10:06.817077: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1006878720 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000/100000 [==============================] - 687s 7ms/step - loss: 34.8556\n",
      "Epoch 3/10\n",
      " 79627/100000 [======================>.......] - ETA: 2:17 - loss: 34.8193"
     ]
    }
   ],
   "source": [
    "i = -1\n",
    "\n",
    "# \"Opera Game\" played by Paul Morphy\n",
    "fen = \"1r3rk1/pp3ppp/3B4/2B1Pb2/q4N2/8/P3QPPP/R4RK1 b - - 6 17\"\n",
    "prediction = predict(fen)\n",
    "print(f\"i: {i} Opera prediction: {prediction}\")\n",
    "\n",
    "fen = \"r3r1k1/pp3pbp/1qp1b1p1/2B5/2BP4/Q1n2N2/P4PPP/3R1K1R w - - 0 18\"\n",
    "prediction = predict(fen)\n",
    "print(f\"i: {i} Donald Byrne and Bobby Fischer 1956 prediction: {prediction}\")\n",
    "\n",
    "fen = \"r1bq1rk1/pp3pbp/2nppnp1/2p5/4P3/2N2NP1/PP1PBPBP/R1BQR1K1 w - - 0 18\"\n",
    "prediction = predict(fen)\n",
    "print(f\"i: {i} Garry Kasparov and Anatoly Karpov 1985 prediction: {prediction}\")\n",
    "\n",
    "\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for i in range(0, 100, 10):\n",
    "    history = model.fit(dataset_subset, epochs=epochs, callbacks=[tb_callback])  # adjust epochs according to your need\n",
    "    # Plot training & validation loss values\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train'], loc='upper left')\n",
    "    plt.show()\n",
    "    model.save_weights(f\"./data/my_model-{epochs+i}-{n_data}-{batch_size}.keras\")\n",
    "    model.save(f\"./data/my_model-{str(epochs+i).zfill(3)}-{str(n_data).zfill(5)}-{str(batch_size).zfill(2)}.h5\")\n",
    "    \n",
    "    # \"Opera Game\" played by Paul Morphy\n",
    "    fen = \"1r3rk1/pp3ppp/3B4/2B1Pb2/q4N2/8/P3QPPP/R4RK1 b - - 6 17\"\n",
    "    prediction = predict(fen)\n",
    "    print(f\"i: {i} Opera prediction: {prediction}\")\n",
    "    \n",
    "    fen = \"r3r1k1/pp3pbp/1qp1b1p1/2B5/2BP4/Q1n2N2/P4PPP/3R1K1R w - - 0 18\"\n",
    "    prediction = predict(fen)\n",
    "    print(f\"i: {i} Donald Byrne and Bobby Fischer 1956 prediction: {prediction}\")\n",
    "\n",
    "    fen = \"r1bq1rk1/pp3pbp/2nppnp1/2p5/4P3/2N2NP1/PP1PBPBP/R1BQR1K1 w - - 0 18\"\n",
    "    prediction = predict(fen)\n",
    "    print(f\"i: {i} Garry Kasparov and Anatoly Karpov 1985 prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b7d7d-11b1-4f73-b274-538343afb208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
